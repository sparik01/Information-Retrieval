{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval: Programming Assignment \\#4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sheetal Parikh\n",
    "EN.605.744.81<br>\n",
    "November 1, 2021\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import os \n",
    "import csv\n",
    "\n",
    "# change the current directory \n",
    "# to specified directory \n",
    "os.chdir(r\"C:\\Users\\Sheetal\\Documents\\Sheetal\\datasets\") \n",
    "\n",
    "#checking current directory\n",
    "#print(os.getcwd() + \"\\n\")\n",
    "\n",
    "#direct path to files\n",
    "filepath_test = '/Users/Sheetal/Documents/Sheetal/datasets/phase1.test.shuf.tsv'\n",
    "filepath_dev = '/Users/Sheetal/Documents/Sheetal/datasets/phase1.dev.shuf.tsv'\n",
    "filepath_train = '/Users/Sheetal/Documents/Sheetal/datasets/phase1.train.shuf.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA and Reading in Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in files\n",
    "\n",
    "train = pd.read_csv(filepath_train, sep='\\t', header=None,\n",
    "       names=[\"Assessment\", \"Docid\", \"Title\", \"Authors\", \"Journal\", \"Issn\", \"Year\", \"Language\", \"Abstract\", \"Keywords\"])\n",
    "\n",
    "dev = pd.read_csv(filepath_dev, sep='\\t', header=None,\n",
    "       names=[\"Assessment\", \"Docid\", \"Title\", \"Authors\", \"Journal\", \"Issn\", \"Year\", \"Language\", \"Abstract\", \"Keywords\"])\n",
    "\n",
    "test = pd.read_csv(filepath_test, sep='\\t', header=None,\n",
    "       names=[\"Assessment\", \"Docid\", \"Title\", \"Authors\", \"Journal\", \"Issn\", \"Year\", \"Language\", \"Abstract\", \"Keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N rows=21662, M columns=10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assessment</th>\n",
       "      <th>Docid</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Issn</th>\n",
       "      <th>Year</th>\n",
       "      <th>Language</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>hash:3f1ebe70-a242-3b43-843c-eef89284607a</td>\n",
       "      <td>Misoprostol for treating postpartum haemorrhag...</td>\n",
       "      <td>Hofmeyr, G. J.;Ferreira, S.;Nikodem, V. C.;Man...</td>\n",
       "      <td>BMC Pregnancy and Childbirth</td>\n",
       "      <td>1471-2393</td>\n",
       "      <td>2004</td>\n",
       "      <td>eng</td>\n",
       "      <td>Background: Postpartum haemorrhage remains an ...</td>\n",
       "      <td>South Africa;adult;article;blood transfusion;c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>hash:aa35378f-0460-37f1-b001-ac735e027333</td>\n",
       "      <td>Vitamin A supplements and diarrheal and respir...</td>\n",
       "      <td>Fawzi, W. W.;Mbise, R.;Spiegelman, D.;Fataki, ...</td>\n",
       "      <td>J Pediatr</td>\n",
       "      <td>0022-3476</td>\n",
       "      <td>2000</td>\n",
       "      <td>eng</td>\n",
       "      <td>OBJECTIVE: To determine the effect of vitamin ...</td>\n",
       "      <td>Child, Preschool;Diarrhea/ epidemiology;Dietar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>hash:3ddd7e14-a607-3313-a74f-613c988206f3</td>\n",
       "      <td>The efficacy and safety of a controlled releas...</td>\n",
       "      <td>Gathua, S. N.;Aluoch, J. A.</td>\n",
       "      <td>East Afr Med J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990</td>\n",
       "      <td>eng</td>\n",
       "      <td>The treatment of asthma in Africa is influence...</td>\n",
       "      <td>Adult;Albuterol/administration &amp; dosage/advers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>hash:41e91fb1-6cfe-3347-aa26-4424e0afe11e</td>\n",
       "      <td>The state of the art of education for child su...</td>\n",
       "      <td>Mrisho, F. H.</td>\n",
       "      <td>BERC Bull</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987</td>\n",
       "      <td>eng</td>\n",
       "      <td>PIP: Tanzania has both a high infant mortality...</td>\n",
       "      <td>Africa;Africa South of the Sahara;Africa, East...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>hash:92d8601c-ef4f-39b1-b65c-ce1c7325ba6f</td>\n",
       "      <td>[The practicability of preceptorship in the cu...</td>\n",
       "      <td>Lin, C. C.;Lo, K. M.;Leu, C. S.</td>\n",
       "      <td>Kaohsiung J Med Sci</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>eng</td>\n",
       "      <td>Physicians who have graduated from traditional...</td>\n",
       "      <td>Adult;Aged;Curriculum;Education, Medical;Engli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Assessment                                      Docid  \\\n",
       "0          -1  hash:3f1ebe70-a242-3b43-843c-eef89284607a   \n",
       "1          -1  hash:aa35378f-0460-37f1-b001-ac735e027333   \n",
       "2          -1  hash:3ddd7e14-a607-3313-a74f-613c988206f3   \n",
       "3          -1  hash:41e91fb1-6cfe-3347-aa26-4424e0afe11e   \n",
       "4          -1  hash:92d8601c-ef4f-39b1-b65c-ce1c7325ba6f   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Misoprostol for treating postpartum haemorrhag...   \n",
       "1  Vitamin A supplements and diarrheal and respir...   \n",
       "2  The efficacy and safety of a controlled releas...   \n",
       "3  The state of the art of education for child su...   \n",
       "4  [The practicability of preceptorship in the cu...   \n",
       "\n",
       "                                             Authors  \\\n",
       "0  Hofmeyr, G. J.;Ferreira, S.;Nikodem, V. C.;Man...   \n",
       "1  Fawzi, W. W.;Mbise, R.;Spiegelman, D.;Fataki, ...   \n",
       "2                        Gathua, S. N.;Aluoch, J. A.   \n",
       "3                                      Mrisho, F. H.   \n",
       "4                    Lin, C. C.;Lo, K. M.;Leu, C. S.   \n",
       "\n",
       "                        Journal       Issn  Year Language  \\\n",
       "0  BMC Pregnancy and Childbirth  1471-2393  2004      eng   \n",
       "1                     J Pediatr  0022-3476  2000      eng   \n",
       "2                East Afr Med J        NaN  1990      eng   \n",
       "3                     BERC Bull        NaN  1987      eng   \n",
       "4           Kaohsiung J Med Sci        NaN  1996      eng   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Background: Postpartum haemorrhage remains an ...   \n",
       "1  OBJECTIVE: To determine the effect of vitamin ...   \n",
       "2  The treatment of asthma in Africa is influence...   \n",
       "3  PIP: Tanzania has both a high infant mortality...   \n",
       "4  Physicians who have graduated from traditional...   \n",
       "\n",
       "                                            Keywords  \n",
       "0  South Africa;adult;article;blood transfusion;c...  \n",
       "1  Child, Preschool;Diarrhea/ epidemiology;Dietar...  \n",
       "2  Adult;Albuterol/administration & dosage/advers...  \n",
       "3  Africa;Africa South of the Sahara;Africa, East...  \n",
       "4  Adult;Aged;Curriculum;Education, Medical;Engli...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check for train file\n",
    "print(f'N rows={len(train)}, M columns={len(train.columns)}')\n",
    "\n",
    "#print first few rows to visualize the training dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assessment       0\n",
       "Docid            0\n",
       "Title            0\n",
       "Authors        412\n",
       "Journal        825\n",
       "Issn          8240\n",
       "Year           681\n",
       "Language         1\n",
       "Abstract         1\n",
       "Keywords       750\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values in training set\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assessment       0\n",
       "Docid            0\n",
       "Title            0\n",
       "Authors          0\n",
       "Journal        168\n",
       "Issn          1845\n",
       "Year           139\n",
       "Language         0\n",
       "Abstract         0\n",
       "Keywords       164\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values in dev set\n",
    "dev.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assessment       0\n",
       "Docid            0\n",
       "Title            0\n",
       "Authors          0\n",
       "Journal        182\n",
       "Issn          1825\n",
       "Year           164\n",
       "Language         0\n",
       "Abstract         0\n",
       "Keywords       142\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values in test set\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21662 entries, 0 to 21661\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Assessment  21662 non-null  int64 \n",
      " 1   Docid       21662 non-null  object\n",
      " 2   Title       21662 non-null  object\n",
      " 3   Authors     21250 non-null  object\n",
      " 4   Journal     20837 non-null  object\n",
      " 5   Issn        13422 non-null  object\n",
      " 6   Year        20981 non-null  object\n",
      " 7   Language    21661 non-null  object\n",
      " 8   Abstract    21661 non-null  object\n",
      " 9   Keywords    20912 non-null  object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#summary of attributes\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eng    21625\n",
       "fre       13\n",
       "spa        9\n",
       "por        8\n",
       "ger        2\n",
       "chi        2\n",
       "afr        1\n",
       "dut        1\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for the number of languages that are present in the training dataset\n",
    "pd.value_counts(train.Language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, all files contain null values. This won't be an issue for the first test since we are only using the title features.  However, we will have to clean the files when using features from the title, keyword, and abstract.  Primarily the keyword columns contains many null values.  Also, we can see that most of the documents are in english so I think it would be sufficient to remove \"english\" stop words.  I don't believe that language would be a good feature to use since it probably won't help distinguish anything since most documents are in english. The Issn column would probably also not be a good feature to use since it contains so many null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulas for Recall, Precision and F1 - Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CountVectorizer from the scikit-learn library will be used to convert the text to numerical data by transforming the \n",
    "text into a vector depending on the count of each word in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating precision of the predicted values\n",
    "#Recall is the percentage of +1s in the Dev file that were correctly predicted to belong to the class; precision\n",
    "#is the percentage of +1s in the output file (or that you predict are positive) which are indeed correct according to the \n",
    "#Dev file labels.\n",
    "\n",
    "#formula for recall - percentage of +1s that are correctly predicted to belong\n",
    "def calc_recall(predictions, actual, wording = True):\n",
    "    total_pred = 0\n",
    "    correct_pred = 0\n",
    "    \n",
    "    #tallying number of total predictions and number of correct predictions\n",
    "    for p, a in zip(predictions, actual):\n",
    "        if a == 1:\n",
    "            total_pred += 1\n",
    "            \n",
    "            if p == 1:\n",
    "                correct_pred += 1\n",
    "    #wording can be turned off if needed\n",
    "    if wording:\n",
    "        print(f'Recall: {correct_pred}/{total_pred} = {correct_pred/total_pred}')\n",
    "    \n",
    "    return correct_pred/total_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formula for precision - percentage of +1s that are correctly predicted according to Dev file labels\n",
    "def calc_precision(predictions, actual, wording = True):\n",
    "    total_pred = 0\n",
    "    correct_pred = 0\n",
    "    \n",
    "    #tallying number of total predictions and number of correct predictions\n",
    "    for p, a in zip(predictions, actual):\n",
    "        if p == 1:\n",
    "            total_pred += 1\n",
    "            \n",
    "            if a == 1:\n",
    "                correct_pred += 1\n",
    "    #wording can be turned off if needed\n",
    "    if wording:\n",
    "        print(f'Precision: {correct_pred}/{total_pred} = {correct_pred/total_pred}')\n",
    "    \n",
    "    return correct_pred/total_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formula for F1 Score:\n",
    "def f1_score(predictions, actual):\n",
    "    p = calc_precision(predictions, actual, wording = False)\n",
    "    r = calc_recall(predictions, actual, wording = False)\n",
    "    \n",
    "    return 2*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for printing all the results\n",
    "def printResults(pred, data):\n",
    "    calc_precision(pred, data)\n",
    "    calc_recall(pred, data)\n",
    "    f1 = f1_score(pred, data)\n",
    "    print(f'F1-Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model - BinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline - Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the results if we try to predict the training set assessment values if only using the title features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Misoprostol for treating postpartum haemorrhag...\n",
       "1    Vitamin A supplements and diarrheal and respir...\n",
       "2    The efficacy and safety of a controlled releas...\n",
       "3    The state of the art of education for child su...\n",
       "4    [The practicability of preceptorship in the cu...\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only extracting features from title from dev file\n",
    "train_title = train['Title']\n",
    "train_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10171)\t1\n",
      "  (0, 16052)\t1\n",
      "  (0, 12357)\t1\n",
      "  (0, 7072)\t1\n",
      "  (0, 13143)\t1\n",
      "  (0, 3919)\t1\n",
      "  (0, 16070)\t1\n",
      "  (0, 8591)\t1\n"
     ]
    }
   ],
   "source": [
    "#creating feature vectors of only the title column - removing stopwords\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_title_vectors = vectorizer.fit_transform(train_title)\n",
    "print(train_title_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the naive bayes the model - using training\n",
    "train_assessment = train['Assessment']\n",
    "model = BernoulliNB(alpha=.01).fit(train_title_vectors, train_assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 611/1099 = 0.5559599636032757\n",
      "Recall: 611/695 = 0.879136690647482\n",
      "F1-Score: 0.6811594202898551\n"
     ]
    }
   ],
   "source": [
    "#baseline training set\n",
    "predictions = model.predict(train_title_vectors)\n",
    "printResults(predictions, train_assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline - Dev File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the results of using the training set to train the model to predict the dev assessment values.  We will only be using the title features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Educational needs in patient care practices in...\n",
       "1    Methods, equipment and techniques for rural he...\n",
       "2    Limitations in verbal fluency following heavy ...\n",
       "3    Attitude towards rape: a comparative study amo...\n",
       "4    An evaluation of a training workshop for pharm...\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only extracting features from title from dev file\n",
    "dev_title = dev['Title']\n",
    "dev_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature vectors\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_title_vectors = vectorizer.fit_transform(train_title)\n",
    "\n",
    "#building model\n",
    "model_nb = BernoulliNB(alpha=.01).fit(train_title_vectors, train_assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting assessment results\n",
    "dev_title_vectors = vectorizer.transform(dev_title)\n",
    "pred_nb =model_nb.predict(dev_title_vectors)\n",
    "dev_assessment = dev['Assessment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2888)\t1\n",
      "  (0, 5255)\t1\n",
      "  (0, 7488)\t1\n",
      "  (0, 8949)\t1\n",
      "  (0, 10661)\t1\n",
      "  (0, 11750)\t1\n",
      "  (0, 12411)\t1\n"
     ]
    }
   ],
   "source": [
    "#viewing the feature vectors\n",
    "print(dev_title_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 60/178 = 0.33707865168539325\n",
      "Recall: 60/150 = 0.4\n",
      "F1-Score: 0.3658536585365853\n"
     ]
    }
   ],
   "source": [
    "#printing resutls\n",
    "printResults(pred_nb, dev_assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Features from Title, Abstract and Keywords Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of NA's in the keyword fields, I chose to drop those rows. A better way to handle the NA's may have been to compare the Abstracts of documents and copy the keywords depending on how similar the Abstracts are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assessment    0\n",
       "Docid         0\n",
       "Title         0\n",
       "Authors       0\n",
       "Journal       0\n",
       "Issn          0\n",
       "Year          0\n",
       "Language      0\n",
       "Abstract      0\n",
       "Keywords      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all NA's in training set\n",
    "train_2 = train.dropna()\n",
    "\n",
    "#checking if NAs have dropped\n",
    "train_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Misoprostol for treating postpartum haemorrhag...\n",
       "1        Vitamin A supplements and diarrheal and respir...\n",
       "5        Yad L'hakhlama (Reach to Recovery) in IsraelYa...\n",
       "10       [Knowledge and treatment of malaria in rural S...\n",
       "12       Emergency aortic stent grafting for traumatic ...\n",
       "                               ...                        \n",
       "21654    Prevalence of Chlamydia trachomatis infection ...\n",
       "21657    155 vascular injuries: a retrospective study i...\n",
       "21658    Clinicians' perceptions of the problem of anti...\n",
       "21659    Histopathology services in a rural African hos...\n",
       "21660    An audit of structure, process and outcome of ...\n",
       "Length: 12887, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating list of all title, abstract and keyword features using train set without NAs\n",
    "train_list = train_2['Title'] + train_2['Abstract'] + train_2['Keywords']\n",
    "train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Educational needs in patient care practices in...\n",
       "1       Methods, equipment and techniques for rural he...\n",
       "2       Limitations in verbal fluency following heavy ...\n",
       "5       A pilot study of gender inequalities related t...\n",
       "6       Optimal staffing for Acute Care of the Elderly...\n",
       "                              ...                        \n",
       "4843    Knowledge, attitude, the perceived risks of in...\n",
       "4845    Effects on age on spinal cord lesion patients'...\n",
       "4846    Malaria: knowledge and behaviour in an endemic...\n",
       "4847    Coronary artery disease is associated with the...\n",
       "4849    Dermatophytomycoses in children in rural Kenya...\n",
       "Length: 2922, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all NA's in dev set\n",
    "dev2 = dev.dropna()\n",
    "dev_data = dev2['Title'] + dev2['Abstract'] + dev2['Keywords']\n",
    "dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature vectors \n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_title_vectors = vectorizer.fit_transform(train_list)\n",
    "\n",
    "#creating model\n",
    "model_nb2 = BernoulliNB(alpha=.001).fit(train_title_vectors, train_2['Assessment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 42/90 = 0.4666666666666667\n",
      "Recall: 42/101 = 0.4158415841584158\n",
      "F1-Score: 0.43979057591623033\n"
     ]
    }
   ],
   "source": [
    "dev_title_vectors = vectorizer.transform(dev_data)\n",
    "pred_nb2 = model_nb2.predict(dev_title_vectors)\n",
    "\n",
    "printResults(pred_nb2, dev2['Assessment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the naive bayes model using the title, abstract and keyword features resulted in a better recall, precision and F1-score than when only using the title.  For the SVM and Logistic Regression models below, I'll be using the title, abstract and keyword features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training feature vectors\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model\n",
    "model_svc = svm.LinearSVC(max_iter = 4000).fit(train_vectors, train_2['Assessment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 46/103 = 0.44660194174757284\n",
      "Recall: 46/101 = 0.45544554455445546\n",
      "F1-Score: 0.4509803921568628\n"
     ]
    }
   ],
   "source": [
    "#predicting assessment results of dev file \n",
    "dev_vectors = vectorizer.transform(dev_data)\n",
    "preds_svm = model_svc.predict(dev_vectors)\n",
    "\n",
    "#view results\n",
    "printResults(preds_svm, dev2['Assessment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model performed better than the Naive Bayes model using the title, abstract, and keyword features and after having removed all the NA's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set feature vectors\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model\n",
    "model_lr = LogisticRegression(max_iter = 1000).fit(train_vectors, train_2['Assessment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 44/87 = 0.5057471264367817\n",
      "Recall: 44/101 = 0.43564356435643564\n",
      "F1-Score: 0.4680851063829788\n"
     ]
    }
   ],
   "source": [
    "#predicting assessment results of dev file \n",
    "dev_vectors = vectorizer.transform(dev_data)\n",
    "preds_lr = model_lr.predict(dev_vectors)\n",
    "\n",
    "#view results\n",
    "printResults(preds_lr,dev2['Assessment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model produced the best results with a precision of around 50%, recall around 44% and \n",
    "an F1-Score of around 47%.  Similar to the SVM model, I used the title, abstract and keyword features using the training and dev dataset after removing all rows with NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression and Adding Journal Features - Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Educational needs in patient care practices in...\n",
       "1       Methods, equipment and techniques for rural he...\n",
       "2       Limitations in verbal fluency following heavy ...\n",
       "5       A pilot study of gender inequalities related t...\n",
       "6       Optimal staffing for Acute Care of the Elderly...\n",
       "                              ...                        \n",
       "4843    Knowledge, attitude, the perceived risks of in...\n",
       "4845    Effects on age on spinal cord lesion patients'...\n",
       "4846    Malaria: knowledge and behaviour in an endemic...\n",
       "4847    Coronary artery disease is associated with the...\n",
       "4849    Dermatophytomycoses in children in rural Kenya...\n",
       "Length: 2922, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating feature vectors of the dev data\n",
    "dev_data2 = dev2['Title'] + dev2['Abstract'] + dev2['Keywords'] + dev2['Journal']\n",
    "dev_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature vectors of the training data\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_title_vectors = vectorizer.fit_transform(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building logistic regression model\n",
    "model_lr2 = LogisticRegression(max_iter = 1000).fit(train_title_vectors, train_2['Assessment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 42/85 = 0.49411764705882355\n",
      "Recall: 42/101 = 0.4158415841584158\n",
      "F1-Score: 0.4516129032258065\n"
     ]
    }
   ],
   "source": [
    "#prediction results\n",
    "dev_title_vectors = vectorizer.transform(dev_data2)\n",
    "preds_lr2 = model_lr2.predict(dev_title_vectors)\n",
    "\n",
    "#view results\n",
    "printResults(preds_lr2,dev2['Assessment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, I chose to use the same logistic regression model but added the journal feature.  This produced \n",
    "slightly lower results to the previous experiment of using the logistic fregression model and only the title, abstract,\n",
    "and keyword features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Test File of Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results above, I will use the logistic regression model to create the test set predictions as this model had the highest precision, recall and F1-Score. Also, I used the title, abstract, and keyword features as this also produced the best results. Similar to the other experiments, I had to remove the NA's from the test set as it was causing errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing any NA's from the set\n",
    "test2 = test.dropna()\n",
    "\n",
    "#creating list of features for the test set\n",
    "test_data = test2['Title'] + test2['Abstract'] + test2['Keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature vectors for training set\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_title_vectors = vectorizer.fit_transform(train_list)\n",
    "\n",
    "#creating model\n",
    "model_lr3 = LogisticRegression(max_iter = 1000).fit(train_title_vectors, train_2['Assessment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature vectors of test set \n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "#test set predictions\n",
    "preds_lr3 = model_lr3.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save prediction by docid in txt file \n",
    "\n",
    "def save_preds(_fn, _y_pred, _df):\n",
    "    import csv\n",
    "    with open(_fn, 'w') as fout:\n",
    "        writer = csv.writer(fout, delimiter=',', lineterminator='\\n')\n",
    "        writer.writerow(['Docid', 'Assessment'])\n",
    "        for y, docID in zip(_y_pred, _df['Docid']):\n",
    "            writer.writerow([docID, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the prediction results to a txt file\n",
    "save_preds('SPARIKH6.txt', preds_lr3, test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Docid</th>\n",
       "      <th>Assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hash:518a02c1-75f6-3e00-8575-de6ee4ca0e32</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hash:54c7ea79-9c8a-38b3-95c7-a0def1df161d</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hash:0ffaac73-5a77-3a7d-bd07-33e495cf577d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hash:6fb4a864-953e-3e60-9b86-778872647be5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hash:7aece21e-e933-3702-984c-a3efb6cc8595</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Docid  Assessment\n",
       "0  hash:518a02c1-75f6-3e00-8575-de6ee4ca0e32          -1\n",
       "1  hash:54c7ea79-9c8a-38b3-95c7-a0def1df161d          -1\n",
       "2  hash:0ffaac73-5a77-3a7d-bd07-33e495cf577d           1\n",
       "3  hash:6fb4a864-953e-3e60-9b86-778872647be5          -1\n",
       "4  hash:7aece21e-e933-3702-984c-a3efb6cc8595          -1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in txt file\n",
    "pred_results = pd.read_csv('SPARIKH6.txt', sep=',')\n",
    "pred_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2858\n",
       " 1      67\n",
       "Name: Assessment, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the assessment results\n",
    "pd.value_counts(pred_results.Assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the predicted values of the test file is also highly skewed toward -1, similar to the dev and training sets.  I believe this skew in data is one of the reasons I wasn't able to produce an F1-Score of above 47%. The model would perform better if we had a more even spread in the data.  Also, there was a lot of missing data.  Rather than simply removing the rows with NAs, it may have been beneficial to come up with a method to replace the NAs with an estimated text value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pythonpool.com/read-tsv-file-python/\n",
    "\n",
    "https://kavita-ganesan.com/news-classifier-with-logistic-regression-in-python/#.YX7uqp5Kg2x\n",
    "\n",
    "https://towardsdatascience.com/basics-of-countvectorizer-e26677900f9c\n",
    "\n",
    "https://towardsdatascience.com/text-classification-using-naive-bayes-theory-a-working-example-2ef4b7eb7d5a\n",
    "\n",
    "https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
